{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Autotagging Using AWS GPU \n",
    "\n",
    "This Project was build in AWS, it use local connection to the dataset, LSTM running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: np_utils in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: future>=0.16 in /jet/lib/python3.6/site-packages (from np_utils)\n",
      "Requirement already satisfied: numpy>=1.0 in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg (from np_utils)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: theano in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six>=1.9.0 in /jet/lib/python3.6/site-packages (from theano)\n",
      "Requirement already satisfied: scipy>=0.14 in /jet/lib/python3.6/site-packages (from theano)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg (from theano)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scikit-learn in /jet/lib/python3.6/site-packages (from sklearn)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflearn in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: Pillow in /jet/lib/python3.6/site-packages (from tflearn)\n",
      "Requirement already satisfied: numpy in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg (from tflearn)\n",
      "Requirement already satisfied: six in /jet/lib/python3.6/site-packages (from tflearn)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /jet/lib/python3.6/site-packages (from boto3)\n",
      "Requirement already satisfied: botocore<1.11.0,>=1.10.60 in /jet/lib/python3.6/site-packages (from boto3)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /jet/lib/python3.6/site-packages (from boto3)\n",
      "Requirement already satisfied: docutils>=0.10 in /jet/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.60->boto3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /jet/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.60->boto3)\n",
      "Requirement already satisfied: six>=1.5 in /jet/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.11.0,>=1.10.60->boto3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlite3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement sqlite3 (from versions: )\n",
      "No matching distribution found for sqlite3\n",
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.8.0 in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg (from tables)\n",
      "Requirement already satisfied: six>=1.9.0 in /jet/lib/python3.6/site-packages (from tables)\n",
      "Requirement already satisfied: numexpr>=2.5.2 in /jet/lib/python3.6/site-packages (from tables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "pip.main(['install', 'np_utils'])\n",
    "pip.main(['install', 'theano'])\n",
    "pip.main(['install', 'sklearn'])\n",
    "pip.main(['install', 'tflearn'])\n",
    "pip.main(['install', 'boto3'])\n",
    "pip.main(['install', 'sqlite3'])\n",
    "pip.main(['install', 'tables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "From /jet/var/python/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import np_utils\n",
    "import theano\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import keras as ks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import hdf5_getters\n",
    "from os import listdir\n",
    "\n",
    "from itertools import product\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import CuDNNLSTM, Dense,TimeDistributed,Dropout,CuDNNLSTM\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "import sklearn\n",
    "import tflearn\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import boto3\n",
    "import os\n",
    "import tables\n",
    "import sqlite3\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file(path,vec_path,vec_id):\n",
    "    files = listdir(path)\n",
    "    for file_ in files:\n",
    "        if len(file_.split('.'))==2:\n",
    "            vec_path.append(path+'/'+file_)\n",
    "            vec_id.append(file_)\n",
    "        else:\n",
    "            get_file(path+'/'+file_,vec_path,vec_id)\n",
    "    return vec_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tags(c,tid):\n",
    "    tid =  tid.split('.')[0]\n",
    "    sql = \"SELECT tags.tag, tid_tag.val FROM tid_tag, tids, tags WHERE tags.ROWID=tid_tag.tag AND tid_tag.tid=tids.ROWID and tids.tid='%s'\" % tid\n",
    "    \n",
    "    res = c.execute(sql)\n",
    "    data = res.fetchall()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_tags = 50\n",
    "path = '/mnt/snap/data/'\n",
    "tags = pd.read_table('./lastfm_top_tags.txt',sep='\\t',nrows=n_tags,names=['tag','occurrence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vec_path = []\\nvec_id = []\\n%time vec_path = get_file(path,vec_path,vec_id)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''vec_path = []\n",
    "vec_id = []\n",
    "%time vec_path = get_file(path,vec_path,vec_id)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_size=['80000','160000','240000','320000' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start = time.time()\\ncount = 1\\nconn = sqlite3.connect(\\'lastfm_tags.db\\')\\nc = conn.cursor()\\noutput = {}\\nmusic_size = {}\\nfor file_,music_id in zip(vec_path,vec_id):\\n    \\n    \\n    music_tags  = get_tags(c,music_id)\\n    if len (music_tags)==0:\\n        continue\\n    \\n    s = set(np.transpose(music_tags )[0])\\n    intersect = s.intersection(tags[\\'tag\\'])\\n    if len (intersect)==0:\\n        continue\\n   \\n    \\n    h5 = hdf5_getters.open_h5_file_read(file_)\\n    confidence = hdf5_getters.get_segments_confidence(h5)\\n    try:\\n        music_size[len(confidence)].append(file_)\\n        output[len(confidence)].append(music_tags)\\n        \\n    except:\\n        music_size[len(confidence)] = [file_]\\n        output[len(confidence)] = [music_tags]\\n    h5.close()\\n    #confidence_vec.append( confidence)\\n    #loudness_max = ( hdf5_getters.get_segments_loudness_max(h5))\\n    #max_time = (hdf5_getters.get_segments_loudness_max_time(h5))\\n    #loudness_star = (hdf5_getters.get_segments_loudness_start(h5))\\n    \\n    #segments_start = (hdf5_getters.get_segments_start(h5))\\n    \\n    #for i in range(len(segments_timbre)):\\n        #segments_timbre[i] = (np.transpose(hdf5_getters.get_segments_timbre(h5))[i])\\n        #pitches[i] = (np.transpose(hdf5_getters.get_segments_pitches(h5))[i])\\n    #array_id.append([hdf5_getters.get_song_id(h5)])\\n    #array1.append([hdf5_getters.get_song_id(h5)] *len(confidence))\\n    #array2.append( range(len(confidence)))\\n    \\n    \\n    if count%10000==0:\\n        print(count,time.time()-start)\\n    if count%80000==0:\\n        \\n        \\n \\n        json1 = json.dumps(output)\\n        f = open(\"./data/out_dict\"+str(count)+\".json\",\"w\")\\n        f.write(json1)\\n        f.close()\\n        file_sizes = open(\\'./data/size_dict\\'+str(count)+\\'.txt\\',\\'w\\')\\n        keys = np.asarray(list(music_size.keys()))\\n        keys = np.sort(keys)\\n        for key in keys:\\n            value = music_size[key]\\n            value = str(value)\\n            file_sizes.write(str(key)+\\';\\'+value+\\'\\n\\')\\n        file_sizes.close()\\n        output = {}\\n        music_size = {}\\n    count+=1\\nconn.close()    \\njson1 = json.dumps(output)\\nf = open(\"./data/out_dict\"+str(count)+\".json\",\"w\")\\nf.write(json1)\\nf.close()\\nfile_sizes = open(\\'./data/size_dict\\'+str(count)+\\'.txt\\',\\'w\\')\\nkeys = np.asarray(list(music_size.keys()))\\nkeys = np.sort(keys)\\nfor key in keys:\\n    value = music_size[key]\\n    value = str(value)\\n    file_sizes.write(str(key)+\\';\\'+value+\\'\\n\\')\\nfile_sizes.close()\\noutput = {}\\nmusic_size = {}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This part of the code just need to run once to generate the files. This is done, because getting the data was slow \n",
    "#and to expensive to rerun everytime the kernel was initialized or restarted.\n",
    "'''start = time.time()\n",
    "count = 1\n",
    "conn = sqlite3.connect('lastfm_tags.db')\n",
    "c = conn.cursor()\n",
    "output = {}\n",
    "music_size = {}\n",
    "for file_,music_id in zip(vec_path,vec_id):\n",
    "    \n",
    "    \n",
    "    music_tags  = get_tags(c,music_id)\n",
    "    if len (music_tags)==0:\n",
    "        continue\n",
    "    \n",
    "    s = set(np.transpose(music_tags )[0])\n",
    "    intersect = s.intersection(tags['tag'])\n",
    "    if len (intersect)==0:\n",
    "        continue\n",
    "   \n",
    "    \n",
    "    h5 = hdf5_getters.open_h5_file_read(file_)\n",
    "    confidence = hdf5_getters.get_segments_confidence(h5)\n",
    "    try:\n",
    "        music_size[len(confidence)].append(file_)\n",
    "        output[len(confidence)].append(music_tags)\n",
    "        \n",
    "    except:\n",
    "        music_size[len(confidence)] = [file_]\n",
    "        output[len(confidence)] = [music_tags]\n",
    "    h5.close()\n",
    "    \n",
    "    \n",
    "    if count%10000==0:\n",
    "        print(count,time.time()-start)\n",
    "    if count%80000==0:\n",
    "        \n",
    "        \n",
    " \n",
    "        json1 = json.dumps(output)\n",
    "        f = open(\"./data/out_dict\"+str(count)+\".json\",\"w\")\n",
    "        f.write(json1)\n",
    "        f.close()\n",
    "        file_sizes = open('./data/size_dict'+str(count)+'.txt','w')\n",
    "        keys = np.asarray(list(music_size.keys()))\n",
    "        keys = np.sort(keys)\n",
    "        for key in keys:\n",
    "            value = music_size[key]\n",
    "            value = str(value)\n",
    "            file_sizes.write(str(key)+';'+value+'\\n')\n",
    "        file_sizes.close()\n",
    "        output = {}\n",
    "        music_size = {}\n",
    "    count+=1\n",
    "conn.close()    \n",
    "json1 = json.dumps(output)\n",
    "f = open(\"./data/out_dict\"+str(count)+\".json\",\"w\")\n",
    "f.write(json1)\n",
    "f.close()\n",
    "file_sizes = open('./data/size_dict'+str(count)+'.txt','w')\n",
    "keys = np.asarray(list(music_size.keys()))\n",
    "keys = np.sort(keys)\n",
    "for key in keys:\n",
    "    value = music_size[key]\n",
    "    value = str(value)\n",
    "    file_sizes.write(str(key)+';'+value+'\\n')\n",
    "file_sizes.close()\n",
    "output = {}\n",
    "music_size = {}'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_vec_file = open('./data/test_vec.txt','r')\n",
    "test_vec = ast.literal_eval(test_vec_file.readlines()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vec_file = open('./data/train_vec.txt','r')\n",
    "train_path_fixed = ast.literal_eval(train_vec_file.readlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_auc_score(y_true,y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    Arguments:\n",
    "        y_pred: `Tensor`. Predicted values.\n",
    "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"RocAucScore\"):\n",
    "    \n",
    "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        neg = tf.expand_dims(neg, 1)\n",
    "\n",
    "        # original paper suggests performance is robust to exact parameter choice\n",
    "        gamma = 0.2\n",
    "        p     = 3\n",
    "\n",
    "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "\n",
    "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "\n",
    "    return tf.reduce_sum(tf.pow(-masked, p)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mine_auc(y_true,y_pred):\n",
    "    return tflearn.objectives.roc_auc_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "# create model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(CuDNNLSTM(32, return_sequences=False, input_shape=(None, 27)))\n",
    "    #model.add(CuDNNLSTM(32, return_sequences=False,))\n",
    "    #model.add(CuDNNLSTM(32, return_sequences=True,))\n",
    "    #model.add(CuDNNLSTM(32, return_sequences=True,))\n",
    "    #model.add(CuDNNLSTM(32, return_sequences=False,))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add((Dense(n_tags, activation='sigmoid')))\n",
    "    #optimizer = RMSprop(lr=0.0000001)\n",
    "    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss=mine_auc,\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model,epochs,x_train,y_train):\n",
    "    \n",
    "    #model.fit(X_train, y_train callbacks=[roc_callback(training_data=(X_train, y_train),validation_data=(X_test, y_test))])\n",
    "    model.fit(x_train, y_train, batch_size=1, epochs=epochs, shuffle=False, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_vecs():\n",
    "    array1 = []\n",
    "    array2 = []\n",
    "    tuples = []\n",
    "    loudness_vec = []\n",
    "    confidence_vec = []\n",
    "    loudness_max_vec = []\n",
    "    max_time_vec = []\n",
    "    loudness_start_vec = []\n",
    "    pitches_vec = []\n",
    "    segments_start_vec = []\n",
    "    segments_timbre_vec = []\n",
    "    y_train = []\n",
    "    array_id =[]\n",
    "\n",
    "\n",
    "    \n",
    "    for i in range(11):\n",
    "        segments_timbre_vec.append([])\n",
    "        pitches_vec.append([])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return y_train,array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec,max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_musics_informations(array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec,values):\n",
    "    for file_ in values:\n",
    "        \n",
    "        h5 = hdf5_getters.open_h5_file_read(file_)\n",
    "        confidence = hdf5_getters.get_segments_confidence(h5)\n",
    "        \n",
    "        confidence_vec.append( confidence)\n",
    "        loudness_max_vec.append( hdf5_getters.get_segments_loudness_max(h5))\n",
    "        max_time_vec.append(hdf5_getters.get_segments_loudness_max_time(h5))\n",
    "        loudness_start_vec.append(hdf5_getters.get_segments_loudness_start(h5))\n",
    "\n",
    "        segments_start_vec.append(hdf5_getters.get_segments_start(h5))\n",
    "\n",
    "        for i in range(len(segments_timbre_vec)):\n",
    "            segments_timbre_vec[i].append(np.transpose(hdf5_getters.get_segments_timbre(h5))[i])\n",
    "            pitches_vec[i].append(np.transpose(hdf5_getters.get_segments_pitches(h5))[i])\n",
    "        array_id.append([hdf5_getters.get_song_id(h5)])\n",
    "        array1.append([hdf5_getters.get_song_id(h5)] *len(confidence))\n",
    "        array2.append( range(len(confidence)))\n",
    "\n",
    "        h5.close()\n",
    "    return array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_dataset(array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec):\n",
    "    array1 = np.concatenate(array1)\n",
    "    array2 = np.concatenate(array2)\n",
    "    arrays = [array1,array2]\n",
    "    tuples = list(zip(*arrays))\n",
    "    index = pd.MultiIndex.from_tuples(tuples,names=['ID','Tempo'])\n",
    "    pandas_input = [np.concatenate(confidence_vec),np.concatenate(loudness_max_vec),\n",
    "                    np.concatenate(max_time_vec),np.concatenate(loudness_start_vec),\n",
    "\n",
    "                    np.concatenate(segments_start_vec)]\n",
    "    pandas_input = np.transpose(pandas_input)\n",
    "    #pandas_input = np.concatenate(pandas_input,pitches_vec)\n",
    "    #pandas_input = np.concatenate(pandas_input,segments_timbre)\n",
    "    dataframe = pd.DataFrame(pandas_input,index=index,columns=['confidence_vec','loudness_max_vec','max_time_vec',\n",
    "                                                               'loudness_start_vec','segments_start_vec'])\n",
    "    for i in range(len(segments_timbre_vec)):\n",
    "        segments_timbre_vec[i] = np.concatenate(segments_timbre_vec[i])\n",
    "        pitches_vec[i] = np.concatenate(pitches_vec[i])\n",
    "        name_timbre = 'timbre' + str(i)\n",
    "        name_pitches = 'pitch'+ str(i)\n",
    "        dataframe[name_timbre] = segments_timbre_vec[i]\n",
    "        dataframe[name_pitches] = pitches_vec[i]\n",
    "    \n",
    "    \n",
    "    return dataframe,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_output_dataset(tags,output,keys,values,index,array_id):\n",
    "    dataframe_out = pd.DataFrame(index=index,columns=tags['tag'])\n",
    "    dataframe_out=dataframe_out.fillna(value=0)\n",
    "    for i in range(len(array_id)):\n",
    "        music_tags = (set( np.transpose(output[str(keys)][i] )[0]).intersection(set(tags['tag'])))\n",
    "        for tag_col in music_tags:\n",
    "                dataframe_out[tag_col][array_id[i][0]]=1\n",
    "    return dataframe_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_np_array(dataframe):\n",
    "    m,n = len(dataframe.index.levels[0]), len(dataframe.index.levels[1])\n",
    "    arr = dataframe.values.reshape(m,n,-1)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for size in files_size: \\n    print (size)\\n    \\n    \\n    with open('./data/out_dict'+size+'.json') as handle:\\n        output = json.loads(handle.read())\\n    \\n    count = 0\\n    scores = []\\n\\n    file_sizes = pd.read_csv('./data/size_dict'+size+'.txt',sep=';',names=['Key','Values'])\\n    file_sizes.index=file_sizes['Key']\\n    \\n    \\n    break\\noutput\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for size in files_size: \n",
    "    print (size)\n",
    "    \n",
    "    \n",
    "    with open('./data/out_dict'+size+'.json') as handle:\n",
    "        output = json.loads(handle.read())\n",
    "    \n",
    "    count = 0\n",
    "    scores = []\n",
    "\n",
    "    file_sizes = pd.read_csv('./data/size_dict'+size+'.txt',sep=';',names=['Key','Values'])\n",
    "    file_sizes.index=file_sizes['Key']\n",
    "    \n",
    "    \n",
    "    break\n",
    "output'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From /jet/var/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "From /jet/var/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 0 6.477267265319824\n",
      "80000 150 48.18399143218994\n",
      "80000 300 129.14771485328674\n",
      "80000 450 375.61834502220154\n",
      "80000 600 975.282347202301\n",
      "80000 750 1775.413353919983\n",
      "80000 900 2500.4504895210266\n",
      "80000 1050 3013.867310523987\n",
      "80000 1200 3380.584093809128\n",
      "80000 1350 3630.752851486206\n",
      "80000 1500 3820.9651849269867\n",
      "80000 1650 3965.1844251155853\n",
      "80000 1800 4080.9153106212616\n",
      "80000 1950 4181.417778491974\n",
      "80000 2100 4268.53727722168\n",
      "80000 2250 4346.319153308868\n",
      "80000 2400 4413.283097743988\n",
      "80000 2550 4482.013801574707\n",
      "80000 2700 4539.99022769928\n",
      "80000 2850 4594.125570297241\n",
      "80000 3000 4642.781368255615\n",
      "80000 3150 4691.260207653046\n",
      "160000\n",
      "160000 0 4731.106090784073\n",
      "160000 150 4773.109721183777\n",
      "160000 300 4852.9436547756195\n",
      "160000 450 5086.456908941269\n",
      "160000 600 5693.691328048706\n",
      "160000 750 6494.594488143921\n",
      "160000 900 7213.0033440589905\n",
      "160000 1050 7743.870124578476\n",
      "160000 1200 8110.182434558868\n",
      "160000 1350 8362.764414310455\n",
      "160000 1500 8549.368165016174\n",
      "160000 1650 8693.638087511063\n",
      "160000 1800 8809.218911647797\n",
      "160000 1950 8906.74313735962\n",
      "160000 2100 8993.469715356827\n",
      "160000 2250 9072.26787161827\n",
      "160000 2400 9138.961047410965\n",
      "160000 2550 9199.719923973083\n",
      "160000 2700 9256.896352052689\n",
      "160000 2850 9310.624089956284\n",
      "160000 3000 9360.032665252686\n",
      "160000 3150 9406.26542711258\n",
      "240000\n",
      "240000 0 9441.09095621109\n",
      "240000 150 9479.220718383789\n",
      "240000 300 9559.649966478348\n",
      "240000 450 9797.617700338364\n",
      "240000 600 10400.003034830093\n",
      "240000 750 11191.108715295792\n",
      "240000 900 11890.529167413712\n",
      "240000 1050 12435.00440955162\n",
      "240000 1200 12807.421370267868\n",
      "240000 1350 13067.05235171318\n",
      "240000 1500 13253.802966356277\n",
      "240000 1650 13401.387734174728\n",
      "240000 1800 13514.929093837738\n",
      "240000 1950 13621.97764992714\n",
      "240000 2100 13711.239716053009\n",
      "240000 2250 13790.889526844025\n",
      "240000 2400 13856.933335542679\n",
      "240000 2550 13921.344441652298\n",
      "240000 2700 13978.718899965286\n",
      "240000 2850 14032.142673969269\n",
      "240000 3000 14082.802587747574\n",
      "240000 3150 14130.37459397316\n",
      "320000\n",
      "320000 0 14177.638121128082\n",
      "320000 150 14217.486892223358\n",
      "320000 300 14297.155562877655\n",
      "320000 450 14524.281120061874\n",
      "320000 600 15112.47083067894\n",
      "320000 750 15898.90563249588\n",
      "320000 900 16622.52409505844\n",
      "320000 1050 17165.27213025093\n",
      "320000 1200 17543.4518930912\n",
      "320000 1350 17804.241307735443\n",
      "320000 1500 17987.284202337265\n",
      "320000 1650 18133.454780340195\n",
      "320000 1800 18248.30922269821\n",
      "320000 1950 18352.666887044907\n",
      "320000 2100 18439.767914295197\n",
      "320000 2250 18517.718707561493\n",
      "320000 2400 18590.16580224037\n",
      "320000 2550 18650.57785964012\n",
      "320000 2700 18707.579127073288\n",
      "320000 2850 18760.29120707512\n",
      "320000 3000 18810.113258838654\n",
      "320000 3150 18857.292219161987\n",
      "error\n",
      "18892.299742937088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "model = init_model()\n",
    "epochs = 1\n",
    "#epochs_manual=10\n",
    "pred_vec = []\n",
    "real_vec = []\n",
    "camadas = 1\n",
    "try:\n",
    "    for size in files_size: \n",
    "        print (size)\n",
    "\n",
    "\n",
    "        with open('./data/out_dict'+size+'.json') as handle:\n",
    "            output = json.loads(handle.read())\n",
    "\n",
    "        count = 0\n",
    "        scores = []\n",
    "\n",
    "        file_sizes = open('./data/size_dict'+size+'.txt','r')\n",
    "\n",
    "        #for keys in keys_vec:\n",
    "        #    values = music_size[keys]\n",
    "        for line in file_sizes.readlines():\n",
    "\n",
    "            start_time1 = time.time()\n",
    "            keys,values =  line.split(';')\n",
    "            keys = int(keys)\n",
    "            values = np.array(np.matrix(values)).ravel()\n",
    "            intersect_vec = set(values)-set(train_path_fixed)\n",
    "            index_test_vec=[]\n",
    "            if  len(intersect_vec)>0:\n",
    "                for intersect in intersect_vec:\n",
    "                    index_test = (list(values).index(intersect))\n",
    "                    index_test_vec.append(index_test)\n",
    "                values=np.delete(values,index_test_vec)    \n",
    "                output_vec = np.delete(output[str(keys)],index_test_vec)\n",
    "                output[str(keys)] = output_vec\n",
    "            if len(values)<1:\n",
    "                continue\n",
    "            y_train,array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec = init_vecs()\n",
    "            array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec = get_musics_informations(array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec,values)\n",
    "\n",
    "            dataframe,index = generate_input_dataset(array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec) \n",
    "            dataframe_out = generate_output_dataset(tags,output,keys,values,index,array_id)\n",
    "\n",
    "\n",
    "\n",
    "            #dataframe = pd.read_csv('./../datacsv/%s.csv' % keys,index_col = ['ID','Tempo'])\n",
    "            #dataframe_out = pd.read_csv('./../datacsv_out/%s.csv' % keys,index_col = ['ID','Tempo'])\n",
    "\n",
    "            try:\n",
    "                dataframe = to_np_array(dataframe)\n",
    "                dataframe_out = to_np_array(dataframe_out)\n",
    "\n",
    "            except:\n",
    "                log_file = open('log_error_file_test6.txt','a')\n",
    "                log_file.write(str(keys))\n",
    "                log_file.write('\\n')\n",
    "                log_file.close()\n",
    "                continue\n",
    "            y_train = []\n",
    "            for i in range(len(dataframe_out)):\n",
    "                y_train.append(dataframe_out[i][0])\n",
    "\n",
    "\n",
    "            y_train = np.asarray(y_train).reshape((-1, 50))\n",
    "\n",
    "            model = train_model(model,epochs,dataframe,y_train)\n",
    "\n",
    "            datatest = dataframe\n",
    "\n",
    "\n",
    "            if count%25==0:\n",
    "                log_file = open('log_file_25_test6.txt','a')\n",
    "                log_file.write(str(keys)+','+str(time.time()-start_time))\n",
    "                log_file.write('\\n')\n",
    "                log_file.close() \n",
    "\n",
    "            if count%150==0:\n",
    "                print (size,count,(time.time()-start_time))\n",
    "\n",
    "                #print y_pred\n",
    "                #print 'Auc_score: %s' % (str(auc_value))\n",
    "                #model.save('./models/model_auc_%s_l_%s_e_%s_r_%s' % ('2_32',epochs_manual,epochs,it_epochs)) \n",
    "            count +=1\n",
    "\n",
    "            #array_id.append([hdf5_getters.get_song_id(h5)])\n",
    "            #array1.append([hdf5_getters.get_song_id(h5)] *len(confidence))\n",
    "            #array2.append( range(len(confidence)))\n",
    "\n",
    "        model.save('./models/model_auc_%s_%s_%s' % (camadas,epochs,size)) \n",
    "\n",
    "        '''print (sklearn.metrics.roc_auc_score(np.asarray(real_vec), np.asarray(pred_vec),average='macro'))\n",
    "        print (sklearn.metrics.roc_auc_score(np.asarray(real_vec), np.asarray(pred_vec),average='micro'))\n",
    "        print (sklearn.metrics.roc_auc_score(np.asarray(real_vec), np.asarray(pred_vec),average='samples'))'''\n",
    "except:\n",
    "    print('error')\n",
    "print(time.time()-start_time)\n",
    "model.save('./models/model_auc_%s_%s_%s_final' % (camadas,epochs,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = ['_test']\n",
    "model.save('./models/model_auc_%s_%s_%s_final' % (camadas,epochs,size))\n",
    "#model = load_model('./models/model_auc_primeiro',custom_objects={'mine_auc': mine_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_test\n",
      "_test 0 1.4498462677001953 0.30612244898 0.30612244898\n",
      "_test 100 9.854448795318604 0.667817725169 0.682854229133\n",
      "_test 200 26.73434090614319 0.638341093415 0.631991972545\n",
      "_test 300 57.259369134902954 0.609131776256 0.598089835568\n",
      "_test 400 125.06708145141602 0.571457427616 0.552529917325\n",
      "_test 500 283.0502371788025 0.550484388808 0.531315198813\n",
      "_test 600 555.1039144992828 0.551062340536 0.532486049501\n",
      "_test 700 856.5468904972076 0.555874795739 0.53890832629\n",
      "_test 800 1147.2136034965515 0.561948627019 0.547583987539\n",
      "_test 900 1405.506820678711 0.568263531902 0.555653526873\n",
      "_test 1000 1611.6290516853333 0.574203838891 0.562776941033\n",
      "_test 1100 1765.668612241745 0.577824004782 0.567496690793\n",
      "_test 1200 1895.8037152290344 0.581564224129 0.571760608308\n",
      "_test 1300 1993.7796730995178 0.584188896223 0.575172611868\n",
      "_test 1400 2076.9867973327637 0.586472516352 0.578046827466\n",
      "_test 1500 2149.2479898929596 0.588950502147 0.58101083598\n",
      "_test 1600 2211.754189491272 0.590975871716 0.583754831691\n",
      "_test 1700 2268.595301389694 0.592769283068 0.586098986772\n",
      "_test 1800 2318.2711737155914 0.594317290101 0.588093246525\n",
      "_test 1900 2362.0875475406647 0.595561649263 0.589638027312\n",
      "_test 2000 2406.471363067627 0.59684526863 0.591294160461\n",
      "_test 2100 2448.319018602371 0.598130741055 0.59284056145\n",
      "_test 2200 2488.679546356201 0.599299456458 0.594376819606\n",
      "_test 2300 2526.3041985034943 0.600305809249 0.595788679206\n",
      "_test 2400 2561.0767641067505 0.601173689478 0.596841516865\n",
      "_test 2500 2595.5541112422943 0.601949544328 0.59784373785\n",
      "_test 2600 2629.323199748993 0.60273083063 0.598729078384\n",
      "_test 2700 2662.1297178268433 0.603377998634 0.599554034643\n",
      "_test 2800 2693.182083129883 0.60400266604 0.600365367543\n",
      "_test 2900 2724.0475051403046 0.604489342141 0.601061118228\n",
      "_test 3000 2754.656063556671 0.604902586987 0.601603929123\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#epochs_manual=10\n",
    "pred_vec = []\n",
    "real_vec = []\n",
    "for size in test_files: \n",
    "    print (size)\n",
    "    \n",
    "    \n",
    "    with open('./data/out_dict'+size+'.json') as handle:\n",
    "        output = json.loads(handle.read())\n",
    "    \n",
    "    count = 0\n",
    "    scores = []\n",
    "\n",
    "    file_sizes = open('./data/size_dict'+size+'.txt','r')\n",
    "    \n",
    "\n",
    "    for line in file_sizes.readlines():\n",
    "        \n",
    "        start_time1 = time.time()   \n",
    "        keys,values =  line.split(';')\n",
    "        keys = int(keys)\n",
    "        values = np.array(np.matrix(values)).ravel()\n",
    "        \n",
    "        y_train,array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec = init_vecs()\n",
    "        array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec = get_musics_informations(array_id,array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec,values)\n",
    "        \n",
    "        dataframe,index = generate_input_dataset(array1,array2,tuples,loudness_vec,confidence_vec,loudness_max_vec, max_time_vec,loudness_start_vec,pitches_vec,segments_start_vec,segments_timbre_vec) \n",
    "        dataframe_out = generate_output_dataset(tags,output,keys,values,index,array_id)\n",
    "\n",
    "        \n",
    "        \n",
    "        #dataframe = pd.read_csv('./../datacsv/%s.csv' % keys,index_col = ['ID','Tempo'])\n",
    "        #dataframe_out = pd.read_csv('./../datacsv_out/%s.csv' % keys,index_col = ['ID','Tempo'])\n",
    "        \n",
    "        try:\n",
    "            dataframe = to_np_array(dataframe)\n",
    "            dataframe_out = to_np_array(dataframe_out)\n",
    "        \n",
    "        except:\n",
    "            log_file = open('log_error_file_test6txt','a')\n",
    "            log_file.write(str(keys))\n",
    "            log_file.write('\\n')\n",
    "            log_file.close()\n",
    "            continue\n",
    "        y_train = []\n",
    "        for i in range(len(dataframe_out)):\n",
    "            y_train.append(dataframe_out[i][0])\n",
    "\n",
    "\n",
    "        y_train = np.asarray(y_train).reshape((-1, 50))\n",
    "         \n",
    "        for c_mat_it in range(len(y_train)):\n",
    "            y_pred = model.predict(dataframe)\n",
    "            real_vec.append(np.asarray(y_train)[c_mat_it])\n",
    "            pred_vec.append(np.asarray(y_pred)[c_mat_it])\n",
    "            score = sklearn.metrics.roc_auc_score(np.asarray(y_train)[c_mat_it], np.asarray(y_pred)[c_mat_it])\n",
    "            scores.append(score)\n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "        \n",
    "        if count%100==0:\n",
    "            print (size,count,(time.time()-start_time),(str(sklearn.metrics.roc_auc_score(np.asarray(real_vec), np.asarray(pred_vec),average='micro'))),(str(sklearn.metrics.roc_auc_score(np.asarray(real_vec), np.asarray(pred_vec),average='samples'))))\n",
    "            \n",
    "            #print y_pred\n",
    "            #print 'Auc_score: %s' % (str(auc_value))\n",
    "            #model.save('./models/model_auc_%s_l_%s_e_%s_r_%s' % ('2_32',epochs_manual,epochs,it_epochs)) \n",
    "        count +=1\n",
    "        \n",
    "        #array_id.append([hdf5_getters.get_song_id(h5)])\n",
    "        #array1.append([hdf5_getters.get_song_id(h5)] *len(confidence))\n",
    "        #array2.append( range(len(confidence)))\n",
    "    \n",
    "    #print (sklearn.metrics.roc_auc_score(np.asarray(real_vec), np.asarray(pred_vec),average='macro'))\n",
    "    result = open('./out/out_auc_%s_%s.txt' % (camadas,epochs),'w')\n",
    "    result.write('AUC micro: ')\n",
    "    result.write(str(sklearn.metrics.roc_auc_score(np.asarray(real_vec), np.asarray(pred_vec),average='micro')))\n",
    "    result.write('\\nAUC samples: ')\n",
    "    result.write(str(sklearn.metrics.roc_auc_score(np.asarray(real_vec), np.asarray(pred_vec),average='samples')))\n",
    "    result.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prints are only for me to check faster without the need to open the log files. The real analysis was made using the log files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
